{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages (from requests->torchvision) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PredictorNetwork:\n\tsize mismatch for fc.0.weight: copying a param with shape torch.Size([512, 131072]) from checkpoint, the shape in current model is torch.Size([512, 200704]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28708\\957786195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mselector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cbfar\\anaconda3\\envs\\cs221\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1672\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PredictorNetwork:\n\tsize mismatch for fc.0.weight: copying a param with shape torch.Size([512, 131072]) from checkpoint, the shape in current model is torch.Size([512, 200704])."
     ]
    }
   ],
   "source": [
    "from sample import BaseModel, train_predictor, train_selector\n",
    "from sample import PredictorNetwork\n",
    "from sample import SelectorNetwork\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# Load the pretrained ResNet-50 model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "selector = SelectorNetwork(32000)\n",
    "predictor = PredictorNetwork(200704, 32000)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
    "\n",
    "p_model_path = \"models/p_layer1_v1.pth\"\n",
    "s_model_path = \"models/s_layer1_v1.pth\"\n",
    "# Switch to evaluation mode\n",
    "\n",
    "selector.load_state_dict(torch.load(s_model_path))\n",
    "predictor.load_state_dict(torch.load(p_model_path))\n",
    "\n",
    "resnet.eval()\n",
    "selector.eval()\n",
    "predictor.eval()\n",
    "# Transformation and data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Define your input data (example input tensor)\n",
    "# Load the validation dataset\n",
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Iterate through each layer in the ResNet-50 model and apply them sequentially\n",
    "total_start = time.time()\n",
    "\n",
    "for image, labels in val_loader:\n",
    "  output = image\n",
    "  for name, layer in resnet.named_children():\n",
    "      start = time.time()\n",
    "      if name == 'avgpool':\n",
    "          output = nn.functional.adaptive_avg_pool2d(output, (1, 1))\n",
    "      elif name == 'fc':\n",
    "          output = output.view(output.size(0), -1)\n",
    "      elif name == 'layer1':# or name == 'layer2' or name == 'layer3' or name == 'layer4':\n",
    "          output = layer(output)\n",
    "          print(f\"layer1 output shape = {output.shape}\")\n",
    "          pred_out = predictor(output)\n",
    "          if selector(pred_out) == 1:\n",
    "              output = pred_out\n",
    "              break    \n",
    "      else:\n",
    "          output = layer(output)\n",
    "\n",
    "      print(f\"Layer: {name}, Output shape: {output.shape}, total time: {time.time() - start}\")\n",
    "\n",
    "print(f\"total time: {time.time() - total_start}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
